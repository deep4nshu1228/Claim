import shap
import pandas as pd

# Assuming you already have your trained XGBoost model `xgb_model`
# and your training data X (after encoding)

# Get SHAP values
explainer = shap.TreeExplainer(xgb_model)
shap_values = explainer.shap_values(X)

# Create feature importance dataframe
importance_df = pd.DataFrame({
    "feature": X.columns,
    "importance": abs(shap_values).mean(axis=0)
})

# Function to map one-hot features back to original categorical
def map_feature(f):
    if "_" in f:  # assuming encoding is col_category
        return f.split("_")[0]
    return f

importance_df["group"] = importance_df["feature"].apply(map_feature)

# Aggregate importance by group
grouped_importance = (
    importance_df.groupby("group")["importance"]
    .sum()
    .sort_values(ascending=False)
)

print(grouped_importance)




import matplotlib.pyplot as plt

# Assuming grouped_importance is the Series we created (with categorical clubbed)
# Normalize to percentages
grouped_importance_pct = 100 * grouped_importance / grouped_importance.sum()

# Plot
plt.figure(figsize=(10,6))
grouped_importance_pct.plot(kind='bar')

# Add labels
for i, v in enumerate(grouped_importance_pct):
    plt.text(i, v + 0.5, f"{v:.1f}%", ha='center')

plt.title("Feature Importance (Grouped, % Contribution)")
plt.ylabel("Percentage Importance")
plt.xlabel("Features")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()
