1. Error Accumulation in Long-Horizon Forecasting
Description:
When generating forecasts for up to 60 months ahead, prediction errors from earlier months would compound in later months. For example, if the model slightly overestimated costs in month 1, this bias would carry forward and magnify in months 2, 3, and beyond.

Impact:
This drift reduced accuracy for long-term forecasts, making the later months less reliable.

Mitigation:
To limit the propagation of errors, the model was retrained after every six iterations (forecast steps). This ensured that predictions remained grounded in the most recent observed data before proceeding further.

2. Data Leakage in Real-Time Forecasting
Description:
In a live forecasting scenario, it is crucial that the model only uses historical data available up to the month before (M-1) the forecast month (M).

Impact:
If the model had access to M or later data during training, the results would appear artificially accurate in back-testing but fail in real-world forecasting.

Mitigation:
Strict rules were implemented so all features — including rolling statistics, lags, and EMAs — were calculated only from M-1 and earlier months, preventing any inadvertent leakage.

3. Noisy Models Due to VIDA Segment
Description:
VIDA models were new launches and had not yet completed a full 60-month age cycle. Their warranty patterns were inconsistent and showed high month-to-month volatility due to early-life claim fluctuations.

Impact:
Including VIDA data introduced noise into the model, degrading its performance for other models and increasing forecast variance.

Mitigation:
VIDA models were excluded from the training dataset until sufficient historical stability was available for them.

4. Missing Warranty Data for Certain Dispatch Months
Description:
Some dispatch months had no recorded warranty claims despite having vehicles in operation. For example, Splendor units dispatched in 09-2020 had no recorded claims in the warranty dataset.

Impact:
Although these vehicles had valid ages that fell within the forecast horizon, the absence of claim history meant the model still assigned them a predicted cost based on patterns from similar cohorts — potentially inflating forecasts for these dispatch months.

Mitigation:
Identified and flagged such cohorts in the preprocessing stage to track their contribution separately during aggregation and reporting.

5. Volume Drop in Recent Dispatch Months
Description:
Dispatch volumes for the most recent months before the forecast start date showed a notable decline. Since warranty costs are strongly volume-driven, this trend carried forward into the forecast, reducing predicted costs in aggregate outputs.

Impact:
While mathematically correct, this drop could be misinterpreted by stakeholders as an improvement in warranty performance rather than a volume-driven effect.

Mitigation:
Communicated this behavior clearly in forecast interpretation notes, emphasizing that cost reductions were partly due to lower recent dispatch volumes rather than purely improved quality or performance.



7. Filters & Business Rules
Exclude vehicles with dispatch volume < X for a month (to avoid unstable cost per vehicle).

Map plant and model codes consistently across historical changes.

Apply cost caps to avoid influence from exceptional large claims.

8. Evaluation Metrics & Results
Metrics Used:

MAPE (Mean Absolute Percentage Error) for percentage-based accuracy.

R² Score for goodness of fit.

Performance Summary:

Dataset	MAPE	R²
Train	8.9%	0.56
Test	11.5%	0.56

Interpretation:

MAPE < 12% indicates strong accuracy for business forecasting needs.

R² above 0.5 is reasonable given variability in warranty claims.

9. Model Improvements Over Time
Added seasonality handling for claim peaks.

Developed plant-specific models instead of global model for better granularity.

Applied SHAP analysis to understand feature contributions (vehicle age, dispatch volume, model type were most influential).

Introduced long-horizon correction factor for stability.

10. Final Forecast Delivery
Forecast Horizon:

60 months from latest dispatch cohort in dataset.

Output Format:

Excel file with columns: dispatch_month, model, plant, age_month, forecast_cost.

Pivot-table ready for finance and planning teams.

11. Future Enhancements
Incorporate macroeconomic & inflation factors into cost projections.

Use NeuralProphet or deep learning for better seasonality and trend modeling.

Automate model retraining and reporting via CI/CD pipeline and cloud deployment.
