import pandas as pd
import numpy as np
from statsmodels.tsa.statespace.sarimax import SARIMAX
from pmdarima import auto_arima

def fit_arima_trend(ts):
    """
    Fit auto ARIMA or SARIMA to a given univariate time series and return the fitted trend component.
    
    ts: pd.Series indexed by dispatch_month (datetime or period), warranty cost aggregated for plant-model
    
    Returns: pd.Series of fitted values aligned with ts.index
    """
    # Auto-fit seasonal ARIMA model (monthly seasonality: m=12)
    # You can adjust seasonal=True/False based on data and m (period)
    model = auto_arima(ts, seasonal=True, m=12, stepwise=True,
                       suppress_warnings=True, error_action='ignore')
    
    # Fit SARIMAX with the chosen order (p,d,q) and seasonal_order (P,D,Q,m)
    sarimax = SARIMAX(ts,
                      order=model.order,
                      seasonal_order=model.seasonal_order,
                      enforce_stationarity=False,
                      enforce_invertibility=False)
    sarimax_fit = sarimax.fit(disp=False)
    
    # Extract fitted values (in-sample predictions) as trend approximation
    fitted_trend = sarimax_fit.fittedvalues
    return fitted_trend

# Example usage:
# Suppose df has columns: plant, model, dispatch_month (datetime), cost

# Step 1: Aggregate cost by plant, model, dispatch_month
agg = df.groupby(['plant', 'model', 'dispatch_month'])['cost'].sum().reset_index()

# Step 2: Ensure dispatch_month is datetime and sorted
agg['dispatch_month'] = pd.to_datetime(agg['dispatch_month'])
agg = agg.sort_values(['plant', 'model', 'dispatch_month'])

# Step 3: Create a dataframe to store trend feature
trend_features = []

# Step 4: Fit ARIMA/SARIMA per plant-model and extract trend
for (plant, model), group in agg.groupby(['plant', 'model']):
    # Set dispatch_month as index
    ts = group.set_index('dispatch_month')['cost']
    
    # Fill missing months with NaN and then interpolate or fill forward/backward
    ts = ts.asfreq('MS')  # MS = month start frequency
    ts = ts.fillna(method='ffill').fillna(method='bfill')
    
    # Fit ARIMA and get trend
    fitted_trend = fit_arima_trend(ts)
    
    # Store trend with plant, model, dispatch_month indexing
    tmp = fitted_trend.reset_index()
    tmp['plant'] = plant
    tmp['model'] = model
    tmp = tmp.rename(columns={'fittedvalues': 'trend_arima', 'cost': 'trend_arima'})
    
    trend_features.append(tmp[['plant', 'model', 'dispatch_month', 'trend_arima']])

# Combine all trend features into one dataframe
trend_df = pd.concat(trend_features, ignore_index=True)

# Step 5: Merge trend feature back to original dataframe df on plant, model, dispatch_month
df = df.merge(trend_df, on=['plant', 'model', 'dispatch_month'], how='left')

# Now df has a new column 'trend_arima' with the long-term trend extracted by SARIMA

# Use df['trend_arima'] as a feature in your XGBoost model














import pandas as pd
import numpy as np
from statsmodels.tsa.holtwinters import ExponentialSmoothing

# 0) Normalize DISPATCH_MONTH in the main df to monthly start datetime
# Handles int-like (e.g., 202401), string, period, or datetime inputs.
def to_month_start_datetime(s):
    s = pd.to_datetime(s, errors='coerce')
    # Move to first day of month at 00:00
    s = s.dt.to_period('M').dt.to_timestamp('MS')
    return s

df = df.copy()
df['DISPATCH_MONTH'] = to_month_start_datetime(df['DISPATCH_MONTH'])

# Optional: sanity check for rows that could not be parsed
bad = df['DISPATCH_MONTH'].isna().sum()
if bad > 0:
    print(f"Warning: {bad} rows have unparseable DISPATCH_MONTH; they will be dropped from trend merge.")

# 1) Safe Holt–Winters trend extractor
def safe_hw_trend(ts, seasonal_periods=12, seasonal='add', trend='add'):
    ts = ts.copy()
    # Ensure monthly freq
    ts = ts.asfreq('MS')

    if len(ts) == 0 or ts.isna().all():
        return pd.Series(index=ts.index, dtype=float, name='TREND_HW')

    ts_filled = ts.ffill().bfill()
    n = len(ts_filled)

    if n == 1:
        return pd.Series([ts_filled.iloc[0]], index=ts.index, name='TREND_HW')
    if n == 2:
        val = ts_filled.mean()
        return pd.Series([val]*n, index=ts.index, name='TREND_HW')

    use_seasonal = seasonal if n >= 24 else None

    try:
        model = ExponentialSmoothing(
            ts_filled,
            trend=trend,
            seasonal=use_seasonal,
            seasonal_periods=(seasonal_periods if use_seasonal else None),
            initialization_method='estimated'
        )
        fit = model.fit(optimized=True)
        fitted = fit.fittedvalues
    except Exception:
        # EMA fallback
        alpha = 0.3
        ema_vals = []
        ema = ts_filled.iloc[0]
        for x in ts_filled:
            ema = alpha*x + (1-alpha)*ema
            ema_vals.append(ema)
        fitted = pd.Series(ema_vals, index=ts.index)

    fitted.name = 'TREND_HW'
    return fitted

# 2) Build aggregated monthly series with datetime index
agg = (
    df.loc[df['DISPATCH_MONTH'].notna()]
      .groupby(['PLANT','BIKE_GROUPED','DISPATCH_MONTH'], as_index=False)['WARRANTY_COST']
      .sum()
)

# Ensure DISPATCH_MONTH is monthly start datetime here too (safety)
agg['DISPATCH_MONTH'] = to_month_start_datetime(agg['DISPATCH_MONTH'])
agg = agg.sort_values(['PLANT','BIKE_GROUPED','DISPATCH_MONTH'])

# 3) Fit trend per PLANT–BIKE_GROUPED and collect
trend_frames = []
for (plant, bike), g in agg.groupby(['PLANT','BIKE_GROUPED']):
    ts = g.set_index('DISPATCH_MONTH')['WARRANTY_COST']
    # Ensure monthly freq for the series (this creates a full monthly index)
    ts = ts.asfreq('MS')
    trend = safe_hw_trend(ts, seasonal_periods=12, seasonal='add', trend='add')
    tmp = trend.reset_index()  # columns: DISPATCH_MONTH, TREND_HW
    tmp['PLANT'] = plant
    tmp['BIKE_GROUPED'] = bike
    trend_frames.append(tmp[['PLANT','BIKE_GROUPED','DISPATCH_MONTH','TREND_HW']])

trend_df = (
    pd.concat(trend_frames, ignore_index=True)
    if trend_frames else
    pd.DataFrame(columns=['PLANT','BIKE_GROUPED','DISPATCH_MONTH','TREND_HW'])
)

# 4) Ensure DISPATCH_MONTH dtype matches in both dataframes before merge
trend_df['DISPATCH_MONTH'] = to_month_start_datetime(trend_df['DISPATCH_MONTH'])
df['DISPATCH_MONTH'] = to_month_start_datetime(df['DISPATCH_MONTH'])

# 5) Merge back (now both sides are datetime64[ns] at month-start)
df = df.merge(trend_df, on=['PLANT','BIKE_GROUPED','DISPATCH_MONTH'], how='left')

# 6) Fill missing trend values within each PLANT–BIKE_GROUPED
df['TREND_HW'] = (
    df.groupby(['PLANT','BIKE_GROUPED'], group_keys=False)['TREND_HW']
      .apply(lambda s: s.ffill().bfill())
)

# Optional: if any rows still NA (e.g., entirely missing groups), fill with group mean or global mean
if df['TREND_HW'].isna().any():
    df['TREND_HW'] = df['TREND_HW'].fillna(df['TREND_HW'].mean())
